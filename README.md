# ğŸ§  Wojak Reactor  
### Real-Time Facial Expression & Hand Gesture Reactions

**Wojak Reactor** is a real-time emotion and gesture detection system that reacts with custom **Wojak images**.  
It uses **OpenCV** for webcam input and **MediaPipe** for facial and hand landmark detection.  
Built purely for fun, this project helped me explore how real-time computer vision actually works under the hood.

---

## âš™ï¸ Tech Stack

| Category | Tools / Libraries |
|-----------|------------------|
| **Language** | Python 3.11 |
| **Computer Vision** | [OpenCV](https://opencv.org/) â€” video capture, display, image overlays |
| **Landmark Detection** | [MediaPipe](https://developers.google.com/mediapipe) â€” facial & hand tracking |
| **Math & Data Handling** | NumPy â€” geometric calculations and array processing |
| **Runtime** | Local webcam session (no cloud or web app) |

---

## ğŸ’« Features

### Facial Expression Detection
Detects live expressions and maps them to matching Wojak emotions:
- ğŸ˜ **Neutral**  
- ğŸ˜¡ **Angry**  
- ğŸ˜¢ **Sad**   
- ğŸ˜® **Shocked**  
- ğŸ˜´ **Mouth-breather** â€” jaw dropped, relaxed expression  
- ğŸ¤¦ **Stressed** â€” head in hands or squinting with tension  

### âœ‹ Hand Gesture Detection
Recognizes expressive gestures in real time:
- â¤ï¸ Heart shape with both hands â†’ *Love / Support*  
- ğŸ¤¦ Hands covering face â†’ *Stress / Frustration*  

---

## ğŸ§  What Iâ€™m Learning
- How **MediaPipe FaceMesh** and **Hands** models track landmarks in real time.  
- How to compute **angles, distances, and regions** to infer emotion states.  
- Integrating **OpenCV overlays** (bounding boxes, text, triggers) for live feedback.  
- Efficiently handling real-time frame updates at ~30 FPS.  
- How to make local ML pipelines feel interactive and reactive.  

---

## ğŸ§° Setup & Requirements

Create and activate a virtual environment, then install dependencies:

```bash
python3 -m venv venv
source venv/bin/activate
pip install opencv-python mediapipe numpy
python3 wojak_reactor.py
